{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Data Providers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports and also data_provider import for CIFAR-10 and CIFAR-100 datasets\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import re\n",
    "import sys\n",
    "import tarfile\n",
    "from six.moves import urllib\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "from mlp.data_providers import CIFAR10DataProvider, CIFAR100DataProvider\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputting the training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = CIFAR10DataProvider('train', batch_size=50)\n",
    "valid_data = CIFAR10DataProvider('valid', batch_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for creating layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_weights(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=0.1))\n",
    "def new_biases(length):\n",
    "    return tf.Variable(tf.constant(0.1, shape=[length],dtype=tf.float32))\n",
    "\n",
    "def convolutional_layer(inputs,num_input_channels,filter_size,num_filters, nonlinearity=tf.nn.relu):\n",
    "    shape = [filter_size, filter_size, num_input_channels, num_filters]\n",
    "    # Create new weights aka. filters with the given shape.\n",
    "    weights = new_weights(shape=shape)\n",
    "    # Create new biases, one for each filter.\n",
    "    biases = new_biases(length=num_filters)\n",
    "    \n",
    "    outputs = tf.nn.conv2d(inputs, weights, [1, 1, 1, 1], padding='SAME') + biases\n",
    "    outputs = nonlinearity(outputs)\n",
    "    return outputs\n",
    "\n",
    "def max_pooling(inputs):\n",
    "    # Max Pooling\n",
    "    pool = tf.nn.max_pool(inputs, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1],padding='SAME',name='pool')\n",
    "    output = pool\n",
    "    return output\n",
    "# ELU GLORIOT INITIALIZATION\n",
    "def fully_connected_layer(inputs, input_dim, output_dim, nonlinearity=tf.nn.relu):\n",
    "    weights = tf.Variable(\n",
    "        tf.truncated_normal(\n",
    "            [input_dim, output_dim], stddev=2. / (input_dim + output_dim)**0.5), \n",
    "        'weights')\n",
    "    biases = tf.Variable(tf.zeros([output_dim]), 'biases')\n",
    "    outputs = nonlinearity(tf.matmul(inputs, weights) + biases)\n",
    "    return outputs\n",
    "\n",
    "# ELU\n",
    "def fully_connected_layer_elu(inputs, input_dim, output_dim, nonlinearity=tf.nn.elu):\n",
    "    weights = tf.Variable(\n",
    "        tf.truncated_normal(\n",
    "            [input_dim, output_dim], stddev=2. / (input_dim + output_dim)**0.5), \n",
    "        'weights')\n",
    "    biases = tf.Variable(tf.zeros([output_dim]), 'biases')\n",
    "    outputs = nonlinearity(tf.matmul(inputs, weights) + biases)\n",
    "    \n",
    "    return outputs\n",
    "\n",
    "# Leaky RELU\n",
    "def fully_connected_layer_leakrelu(inputs, input_dim, output_dim):\n",
    "    weights = tf.Variable(\n",
    "        tf.truncated_normal(\n",
    "            [input_dim, output_dim], stddev=2. / (input_dim + output_dim)**0.5), \n",
    "        'weights')\n",
    "    biases = tf.Variable(tf.zeros([output_dim]), 'biases')\n",
    "    outputs = (tf.matmul(inputs, weights) + biases)\n",
    "    alpha = 0.01\n",
    "    outputs = tf.maximum(alpha*outputs,outputs)     \n",
    "    return outputs\n",
    "\n",
    "# Dropout with RELU\n",
    "def fully_connected_layer_dropout_relu(inputs, input_dim, output_dim, nonlinearity=tf.nn.relu):\n",
    "    weights = tf.Variable(\n",
    "        tf.truncated_normal(\n",
    "            [input_dim, output_dim], stddev=2. / (input_dim + output_dim)**0.5), \n",
    "        'weights')\n",
    "    biases = tf.Variable(tf.zeros([output_dim]), 'biases')\n",
    "    inputs = tf.nn.dropout(inputs, dropout)\n",
    "    outputs = nonlinearity(tf.matmul(inputs, weights) + biases)\n",
    "    return outputs\n",
    "\n",
    "# Dropout with ELU\n",
    "def fully_connected_layer_dropout_elu(inputs, input_dim, output_dim, nonlinearity=tf.nn.elu):\n",
    "    weights = tf.Variable(\n",
    "        tf.truncated_normal(\n",
    "            [input_dim, output_dim], stddev=2. / (input_dim + output_dim)**0.5), \n",
    "        'weights')\n",
    "    biases = tf.Variable(tf.zeros([output_dim]), 'biases')\n",
    "    inputs = tf.nn.dropout(inputs, dropout)\n",
    "    outputs = nonlinearity(tf.matmul(inputs, weights) + biases)\n",
    "    \n",
    "    return outputs\n",
    "\n",
    "# Leaky RELU\n",
    "def fully_connected_layer_dropout_leakrelu(inputs, input_dim, output_dim):\n",
    "    weights = tf.Variable(\n",
    "        tf.truncated_normal(\n",
    "            [input_dim, output_dim], stddev=2. / (input_dim + output_dim)**0.5), \n",
    "        'weights')\n",
    "    biases = tf.Variable(tf.zeros([output_dim]), 'biases')\n",
    "    inputs = tf.nn.dropout(inputs, dropout)\n",
    "    outputs = (tf.matmul(inputs, weights) + biases)\n",
    "    alpha = 0.01\n",
    "    outputs = tf.maximum(alpha*outputs,outputs)     \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.placeholder(tf.float32, [None, train_data.inputs.shape[1]], 'inputs')\n",
    "targets = tf.placeholder(tf.float32, [None, train_data.num_classes], 'targets')\n",
    "\n",
    "with tf.name_scope('conv-layer-1'):\n",
    "    shape = [-1, 32, 32, 3]\n",
    "    inputs = tf.reshape(inputs, shape=shape)\n",
    "    conv_1 = convolutional_layer(inputs,3,5,32) \n",
    "    \n",
    "# pooling    \n",
    "with tf.name_scope('max-pool-1'):    \n",
    "    conv_1 = max_pooling(conv_1)  \n",
    "    # normalization\n",
    "    #conv_1 = tf.nn.lrn(conv_1, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name='norm1') \n",
    "                          \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "with tf.name_scope('Conv-2'): \n",
    "    conv_2 = convolutional_layer(conv_1,32,5,64) \n",
    "    \n",
    "    # normalization\n",
    "    #conv_2 = tf.nn.lrn(conv_2, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75,name='norm2')\n",
    "    # pooling\n",
    "with tf.name_scope('max-pool-2'):    \n",
    "    conv_2 = max_pooling(conv_2)  \n",
    "    \n",
    "                         \n",
    "new_shape = tf.reshape(conv_2,[-1,8*8*64])\n",
    "\n",
    "with tf.name_scope('fc-layer-1'):\n",
    "    fc_1 = fully_connected_layer(new_shape, 8*8*64, 384)\n",
    "\n",
    "with tf.name_scope('fc-layer-2'):\n",
    "    fc_2= fully_connected_layer(fc_1, 384,384)\n",
    "    \n",
    "    \n",
    "with tf.name_scope('Softmax'): \n",
    "    fc_3=fully_connected_layer(fc_2, 384,10)\n",
    "   \n",
    "    outputs =fc_3\n",
    "with tf.name_scope('error'):\n",
    "    error = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(outputs, targets))\n",
    "with tf.name_scope('accuracy'):\n",
    "    accuracy = tf.reduce_mean(tf.cast(\n",
    "            tf.equal(tf.argmax(outputs, 1), tf.argmax(targets, 1)), \n",
    "            tf.float32))\n",
    "\n",
    "with tf.name_scope('train'):\n",
    "    train_step = tf.train.AdamOptimizer().minimize(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch 01: err(train)=1.72 acc(train)=0.07\n",
      "End of epoch 02: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 03: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 04: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 05: err(train)=2.30 acc(train)=0.10\n",
      "                 err(valid)=2.30 acc(valid)=0.10\n",
      "End of epoch 06: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 07: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 08: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 09: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 10: err(train)=2.30 acc(train)=0.10\n",
      "                 err(valid)=2.30 acc(valid)=0.10\n",
      "End of epoch 11: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 12: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 13: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 14: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 15: err(train)=2.30 acc(train)=0.10\n",
      "                 err(valid)=2.30 acc(valid)=0.10\n",
      "End of epoch 16: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 17: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 18: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 19: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 20: err(train)=2.30 acc(train)=0.10\n",
      "                 err(valid)=2.30 acc(valid)=0.10\n",
      "End of epoch 21: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 22: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 23: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 24: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 25: err(train)=2.30 acc(train)=0.10\n",
      "                 err(valid)=2.30 acc(valid)=0.10\n",
      "End of epoch 26: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 27: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 28: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 29: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 30: err(train)=2.30 acc(train)=0.10\n",
      "                 err(valid)=2.30 acc(valid)=0.10\n",
      "End of epoch 31: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 32: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 33: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 34: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 35: err(train)=2.30 acc(train)=0.10\n",
      "                 err(valid)=2.30 acc(valid)=0.10\n",
      "End of epoch 36: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 37: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 38: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 39: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 40: err(train)=2.30 acc(train)=0.10\n",
      "                 err(valid)=2.30 acc(valid)=0.10\n",
      "End of epoch 41: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 42: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 43: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 44: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 45: err(train)=2.30 acc(train)=0.10\n",
      "                 err(valid)=2.30 acc(valid)=0.10\n",
      "End of epoch 46: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 47: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 48: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 49: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 50: err(train)=2.30 acc(train)=0.10\n",
      "                 err(valid)=2.30 acc(valid)=0.10\n",
      "End of epoch 51: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 52: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 53: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 54: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 55: err(train)=2.30 acc(train)=0.10\n",
      "                 err(valid)=2.30 acc(valid)=0.10\n",
      "End of epoch 56: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 57: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 58: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 59: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 60: err(train)=2.30 acc(train)=0.10\n",
      "                 err(valid)=2.30 acc(valid)=0.10\n",
      "End of epoch 61: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 62: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 63: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 64: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 65: err(train)=2.30 acc(train)=0.10\n",
      "                 err(valid)=2.30 acc(valid)=0.10\n",
      "End of epoch 66: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 67: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 68: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 69: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 70: err(train)=2.30 acc(train)=0.10\n",
      "                 err(valid)=2.30 acc(valid)=0.10\n",
      "End of epoch 71: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 72: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 73: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 74: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 75: err(train)=2.30 acc(train)=0.10\n",
      "                 err(valid)=2.30 acc(valid)=0.10\n",
      "End of epoch 76: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 77: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 78: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 79: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 80: err(train)=2.30 acc(train)=0.10\n",
      "                 err(valid)=2.30 acc(valid)=0.10\n",
      "End of epoch 81: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 82: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 83: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 84: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 85: err(train)=2.30 acc(train)=0.10\n",
      "                 err(valid)=2.30 acc(valid)=0.10\n",
      "End of epoch 86: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 87: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 88: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 89: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 90: err(train)=2.30 acc(train)=0.10\n",
      "                 err(valid)=2.30 acc(valid)=0.10\n",
      "End of epoch 91: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 92: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 93: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 94: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 95: err(train)=2.30 acc(train)=0.10\n",
      "                 err(valid)=2.30 acc(valid)=0.10\n",
      "End of epoch 96: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 97: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 98: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 99: err(train)=2.30 acc(train)=0.10\n",
      "End of epoch 100: err(train)=2.30 acc(train)=0.10\n",
      "                 err(valid)=2.30 acc(valid)=0.10\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for e in range(100):\n",
    "        running_error = 0.\n",
    "        running_accuracy = 0.\n",
    "        for input_batch, target_batch in train_data:\n",
    "            input_batch = np.reshape(input_batch,(-1, 32, 32, 3))  \n",
    "            _, batch_error, batch_acc = sess.run(\n",
    "                [train_step, error, accuracy], \n",
    "                feed_dict={inputs: input_batch, targets: target_batch})\n",
    "            running_error += batch_error\n",
    "            running_accuracy += batch_acc\n",
    "        running_error /= train_data.num_batches\n",
    "        running_accuracy /= train_data.num_batches\n",
    "        print('End of epoch {0:02d}: err(train)={1:.2f} acc(train)={2:.2f}'\n",
    "              .format(e + 1, running_error, running_accuracy))\n",
    "        if (e + 1) % 5 == 0:\n",
    "            valid_error = 0.\n",
    "            valid_accuracy = 0.\n",
    "            for input_batch, target_batch in valid_data:\n",
    "                input_batch = np.reshape(input_batch,(-1, 32, 32, 3))  \n",
    "                batch_error, batch_acc = sess.run(\n",
    "                    [error, accuracy], \n",
    "                    feed_dict={inputs: input_batch, targets: target_batch})\n",
    "                valid_error += batch_error\n",
    "                valid_accuracy += batch_acc\n",
    "            valid_error /= valid_data.num_batches\n",
    "            valid_accuracy /= valid_data.num_batches\n",
    "            print('                 err(valid)={0:.2f} acc(valid)={1:.2f}'\n",
    "                   .format(valid_error, valid_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot the change in the validation and training set error over training.    \n",
    "fig_1 = plt.figure(figsize=(8, 4))\n",
    "ax_1 = fig_1.add_subplot(111)\n",
    "ax_1.set_ylabel('Training Error')\n",
    "ax_1.plot(epo,err_t_1,label='Adam')\n",
    "ax_1.plot(epo, err_t_2,label='GradDes')\n",
    "ax_1.plot(epo, err_t_3, label='AdDel')\n",
    "ax_1.plot(epo, err_t_4, label='AdaGrad')\n",
    "ax_1.plot(epo, err_t_6, label='Momentum')\n",
    "ax_1.plot(epo, err_t_7, label='Ftrl')\n",
    "ax_1.legend(loc=0)\n",
    "ax_1.set_xlabel('Epoch number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
